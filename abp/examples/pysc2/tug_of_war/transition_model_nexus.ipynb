{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "import os\n",
    "import uuid\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "IntTensor = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "unique_id = str(uuid.uuid4())\n",
    "\n",
    "plot = plt.figure()\n",
    "\n",
    "def weights_initialize(module):\n",
    "    if type(module) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        module.bias.data.fill_(0.01)\n",
    "        \n",
    "class _TransModel(nn.Module):\n",
    "    \"\"\" Model for DQN \"\"\"\n",
    "\n",
    "    def __init__(self, input_len, output_len):\n",
    "        super(_TransModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            torch.nn.Linear(input_len, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1.apply(weights_initialize)\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            torch.nn.Linear(1024, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2.apply(weights_initialize)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(256, output_len)\n",
    "        )\n",
    "        self.output_layer.apply(weights_initialize)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.fc1(input)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "class TransModel():\n",
    "    def __init__(self, input_len, ouput_len, learning_rate = 0.0001):\n",
    "        self.model = _TransModel(input_len, ouput_len)\n",
    "        \n",
    "        if use_cuda:\n",
    "            print(\"Using GPU\")\n",
    "            self.model = self.model.cuda()\n",
    "        else:\n",
    "            print(\"Using CPU\")\n",
    "        self.steps = 0\n",
    "        # self.model = nn.DataParallel(self.model)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr = learning_rate)\n",
    "        self.loss_fn = nn.MSELoss(reduction='mean')\n",
    "        \n",
    "        self.steps = 0\n",
    "        \n",
    "    def predict(self, input, steps, learning):\n",
    "        \n",
    "        output = self.model(input).squeeze(1)\n",
    "        #reward, next_state = output[0], output[1:]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def predict_batch(self, input):\n",
    "        output = self.model(input)\n",
    "        #reward, next_state = output[:, 0], output[:, 1:]\n",
    "        return output\n",
    "\n",
    "    def fit(self, state, target_state):\n",
    "        loss = self.loss_fn(state, target_state)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.steps += 1\n",
    "        return loss\n",
    "    \n",
    "    def save(self):\n",
    "        file_path = './models_mb/NEXUS_MODEL.8.10.19.pt'\n",
    "        torch.save(self.model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_plot(x, y, fig, style = 'o'):\n",
    "    x = x * 2000\n",
    "    y = y * 2000\n",
    "    legend = [\n",
    "                \"Match line\",\n",
    "                \"Player 1 Top HP\",\n",
    "                \"Player 1 Bottom HP\",\n",
    "                \"Player 2 Top HP\",\n",
    "                \"Player 2 Bottom HP\",\n",
    "             ]\n",
    "    fig=plt.figure(figsize=(15, 15), dpi= 160, facecolor='w', edgecolor='k')\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_ylim([-100,2100])\n",
    "    ax.set_xlim([-100,2100])\n",
    "    ax.plot(list(range(-100, 2100)),list(range(-100,2100)), \"b--\", alpha=0.05)\n",
    "    for i in range(len(legend) - 1):\n",
    "        #plt.plot(x[:, i].view(-1).tolist(), y[:, i].view(-1).tolist(), style, s = 0.1)\n",
    "        ax.scatter(x[:, i].view(-1).tolist(), y[:, i].view(-1).tolist(),s = 0.5)\n",
    "\n",
    "    plt.title('Ground Truth - Predict of Units')\n",
    "    plt.legend(legend, bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "    plt.xlabel(\"Ground Truth\")\n",
    "    plt.ylabel(\"Predict\")\n",
    "    chartBox = ax.get_position()\n",
    "    ax.set_position([chartBox.x0, chartBox.y0, chartBox.width, chartBox.height])\n",
    "    ax.legend(legend, loc='center left', bbox_to_anchor=(1, 0.8), shadow=True, ncol=1)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99000\n",
      "396000\n",
      "[0.         0.         0.         0.         3.         0.\n",
      " 0.         0.         0.00222222 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         1.         1.         1.\n",
      " 1.         2.        ]\n",
      "[ 100.    0.    0.    0.    3.    0.    0.    0.    2.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    2.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0. 2000. 2000. 2000. 2000.    2.    0.]\n",
      "\n",
      "[0.         0.         0.         0.         0.00222222 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.         1.         2.        ]\n",
      "[1. 1.]\n",
      "\n",
      "(35,)\n",
      "[1. 1.]\n",
      "\n",
      "(35,)\n",
      "[1. 1.]\n",
      "\n",
      "(35,)\n",
      "[1. 1.]\n",
      "(316800, 2) (79200, 2)\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('all_experiences.pt')\n",
    "np.set_printoptions(suppress=True)\n",
    "l = len(data)\n",
    "\n",
    "one_nexus_perspective = [[[],[]] for _ in range(len(data)*4)] # Format data into the state of the lane from the perspective of a single nexus, ground truth is the opposite nexus HP\n",
    "print(len(data))\n",
    "print(len(one_nexus_perspective))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(data)):\n",
    "    #data[i][1] = [ data[i][1][63] / 2000 , data[i][1][64] / 2000 , data[i][1][65] / 2000 , data[i][1][66] / 2000 ]\n",
    "    \n",
    "    data[i][0][0:4] = np.true_divide( data[i][0][0:4], 30) # Normalize P1 top buildings\n",
    "    data[i][0][5:9] = np.true_divide( data[i][0][5:9], 30) # Normalize P2 top buildings\n",
    "    \n",
    "    data[i][0][0:4] = np.true_divide( data[i][0][0:4], 30) # Normalize P1 bottom buildings\n",
    "    data[i][0][5:9] = np.true_divide( data[i][0][5:9], 30) # Normalize P2 bottom buildings\n",
    "    \n",
    "    data[i][0][63] = data[i][0][63] / 2000 # Normalize P1 Top Nexus HP\n",
    "    data[i][0][64] = data[i][0][64] / 2000 # Normalize P2 Top Nexus HP\n",
    "    \n",
    "    data[i][0][65] = data[i][0][65] / 2000 # Normalize P1 Bottom Nexus HP\n",
    "    data[i][0][66] = data[i][0][66] / 2000 # Normalize P2 Bottom Nexus HP\n",
    "\n",
    "    data[i][0][0] = data[i][0][10] / 1500 # Normalize P1 Minerals\n",
    "    \n",
    "    # Re-split into nexus perspective\n",
    "    j = i * 4\n",
    "    # Perspective of P1 Top\n",
    "    one_nexus_perspective[j][0] = np.concatenate((\n",
    "                                                    data[i][0][1:4],   # P1 top buildings\n",
    "                                                    data[i][0][7],     # P1 pylon\n",
    "                                                    data[i][0][8:11],  # P2 top buildings\n",
    "                                                    data[i][0][14],    # P2 pylon\n",
    "                                                    data[i][0][15:27], # P1 Grid 1-4 top\n",
    "                                                    data[i][0][39:51], # P2 Grid 1-4 top\n",
    "                                                    data[i][0][63],    # P1 Top Nexus HP\n",
    "                                                    data[i][0][65],    # P2 Top Nexus HP\n",
    "                                                    data[i][0][67]     # Wave number\n",
    "                                                  ), axis=None)\n",
    "    # Perspective of P1 Top, ground truth = P2 Top\n",
    "    one_nexus_perspective[j][1] = np.concatenate((\n",
    "                                                    data[i][1][63] / 2000, # GT P1 Top Lane\n",
    "                                                    data[i][1][65] / 2000, # GT P2 Top Lane\n",
    "                                                ), axis=None)\n",
    "    # Perspective of P1 Bottom\n",
    "    one_nexus_perspective[j+1][0] = np.concatenate((\n",
    "                                                    data[i][0][4:7],   # P1 bottom buildings\n",
    "                                                    data[i][0][7],     # P1 pylon\n",
    "                                                    data[i][0][11:14], # P2 bottom buildings\n",
    "                                                    data[i][0][14],    # P2 pylon\n",
    "                                                    data[i][0][27:39], # P1 Grid 1-4 bottom\n",
    "                                                    data[i][0][51:63], # P2 Grid 1-4 bottom\n",
    "                                                    data[i][0][64],    # P1 bottom Nexus HP\n",
    "                                                    data[i][0][66],    # P2 bottom Nexus HP\n",
    "                                                    data[i][0][67]     # Wave number\n",
    "                                                  ), axis=None)\n",
    "    # Perspective of P1 Bottom, ground truth = P2 Bottom\n",
    "    one_nexus_perspective[j+1][1] = np.concatenate((\n",
    "                                                    data[i][1][64] / 2000, # GT P1 Bottom Lane\n",
    "                                                    data[i][1][66] / 2000, # GT P2 Bottom Lane\n",
    "                                                ), axis=None) \n",
    "    # Perspective of P2 Top\n",
    "    one_nexus_perspective[j+2][0] = np.concatenate((\n",
    "                                                    data[i][0][8:11],  # P2 top buildings\n",
    "                                                    data[i][0][14],    # P2 pylon\n",
    "                                                    data[i][0][1:4],   # P1 top buildings\n",
    "                                                    data[i][0][7],     # P1 pylon\n",
    "                                                    data[i][0][39:51], # P2 Grid 1-4 top\n",
    "                                                    data[i][0][15:27], # P1 Grid 1-4 top\n",
    "                                                    data[i][0][65],    # P2 Top Nexus HP\n",
    "                                                    data[i][0][63],    # P1 Top Nexus HP\n",
    "                                                    data[i][0][67]     # Wave number\n",
    "                                                  ), axis=None)\n",
    "    # Perspective of P2 Top, ground truth = P1 Top\n",
    "    one_nexus_perspective[j+2][1] =  np.concatenate((\n",
    "                                                    data[i][1][65] / 2000, # GT P2 Top Lane\n",
    "                                                    data[i][1][63] / 2000, # GT P1 Top Lane\n",
    "                                                ), axis=None)\n",
    "    # Perspective of P2 Bottom\n",
    "    one_nexus_perspective[j+3][0] =  np.concatenate((\n",
    "                                                    data[i][0][11:14], # P2 bottom buildings\n",
    "                                                    data[i][0][14],    # P2 pylon\n",
    "                                                    data[i][0][4:7],   # P1 bottom buildings\n",
    "                                                    data[i][0][7],     # P1 pylon\n",
    "                                                    data[i][0][51:63], # P2 Grid 1-4 bottom\n",
    "                                                    data[i][0][27:39], # P1 Grid 1-4 bottom\n",
    "                                                    data[i][0][66],    # P2 bottom Nexus HP\n",
    "                                                    data[i][0][64],    # P1 bottom Nexus HP\n",
    "                                                    data[i][0][67]     # Wave number\n",
    "                                                  ), axis=None) \n",
    "    # Perspective of P2 Bottom, ground truth = P1 Bottom\n",
    "    one_nexus_perspective[j+3][1] = np.concatenate((\n",
    "                                                    data[i][1][66] / 2000, # GT P2 Bottom Lane\n",
    "                                                    data[i][1][64] / 2000, # GT P1 Bottom Lane\n",
    "                                                ), axis=None) \n",
    "\n",
    "print(data[0][0])\n",
    "#print(len(data[0][0]))\n",
    "print(data[0][1])\n",
    "print()\n",
    "print(one_nexus_perspective[0][0])\n",
    "print(one_nexus_perspective[0][1])\n",
    "print()\n",
    "print(one_nexus_perspective[1][0].shape)\n",
    "print(one_nexus_perspective[1][1])\n",
    "print()\n",
    "print(one_nexus_perspective[2][0].shape)\n",
    "print(one_nexus_perspective[2][1])\n",
    "print()\n",
    "print(one_nexus_perspective[3][0].shape)\n",
    "print(one_nexus_perspective[3][1])\n",
    "\n",
    "np.random.shuffle(one_nexus_perspective)\n",
    "\n",
    "l = len(one_nexus_perspective)\n",
    "\n",
    "train_data = np.array(one_nexus_perspective[: int(np.floor(l * 0.8))])\n",
    "test_data = np.array(one_nexus_perspective[int(np.floor(l * 0.8)) : ])\n",
    "\n",
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "batch_size = 128\n",
    "summary_test = SummaryWriter(log_dir = 'nexus-HP-transition-model-report/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.          6.          0.         ...  0.53        1.\n",
      "  24.        ]\n",
      " [ 8.          1.          0.         ...  1.          1.\n",
      "   9.        ]\n",
      " [ 3.          0.          0.         ...  1.          1.\n",
      "   4.        ]\n",
      " ...\n",
      " [ 0.00444444  0.00222222  0.         ...  1.          1.\n",
      "   7.        ]\n",
      " [ 0.00333333  1.          0.         ...  1.          1.\n",
      "   5.        ]\n",
      " [ 0.01111111  7.          0.         ...  1.          0.35\n",
      "  18.        ]]\n",
      "0.007392558590593433\n"
     ]
    }
   ],
   "source": [
    "baseline = np.stack(test_data[:, 0])\n",
    "print(baseline)\n",
    "idx = [32, 33]\n",
    "baseline_hp = baseline[:, idx]\n",
    "\n",
    "bl_next_state_reward = np.stack(test_data[:, 1])\n",
    "\n",
    "mse_baseline = ((baseline_hp - bl_next_state_reward)**2).mean(axis=None)\n",
    "print(mse_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, data, epoch):\n",
    "    state_action = torch.from_numpy(np.stack(data[:, 0])).type(FloatTensor)\n",
    "    next_state_reward = torch.from_numpy(np.stack(data[:, 1])).type(FloatTensor)\n",
    "    \n",
    "    model.model.eval()\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    outputs = model.predict_batch(state_action)\n",
    "\n",
    "    mse = criterion(outputs, next_state_reward)\n",
    "    mse_p1_top = criterion(outputs[:, 0], next_state_reward[:, 0])\n",
    "    mse_p1_bottom = criterion(outputs[:, 1], next_state_reward[:, 1])\n",
    "    mse_p2_top = criterion(outputs[:, 2], next_state_reward[:, 2])\n",
    "    mse_p2_bottom = criterion(outputs[:, 3], next_state_reward[:, 3])\n",
    "\n",
    "    accuracy = torch.sum( torch.sum( torch.eq( outputs, next_state_reward ) )).item()\n",
    "    accuracy = accuracy / (2 * outputs.size()[0])\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        p = dot_plot(next_state_reward, outputs, plot)\n",
    "        p.show()\n",
    "    model.model.train()\n",
    "    \n",
    "    summary_test.add_scalar(\"MSE\", float(mse.item()), epoch)\n",
    "    summary_test.add_scalars(\"MSE\",{'Baseline Nexus HP MSE': float(mse_baseline)}, epoch)\n",
    "\n",
    "    summary_test.add_scalars(\"MSE\",{'Player 1 Top Nexus HP MSE': float(mse_p1_top.item())}, epoch)\n",
    "    summary_test.add_scalars(\"MSE\",{'Player 1 Bottom Nexus HP MSE': float(mse_p1_bottom.item())}, epoch)\n",
    "    \n",
    "    summary_test.add_scalars(\"MSE\",{'Player 2 Top Nexus HP MSE': float(mse_p2_top.item())}, epoch)\n",
    "    summary_test.add_scalars(\"MSE\",{'Player 2 Bottom Nexus HP MSE': float(mse_p2_bottom.item())}, epoch)\n",
    "   \n",
    "    f = open(\"nexus-HP-transition-model-report/test_loss.txt\", \"a+\")\n",
    "    f.write(\"loss:\" + str(mse.item()) + \", \")\n",
    "    f.write(\"acc:\" + str(accuracy) + \"\\n\")\n",
    "    if epoch % 1000 == 0:\n",
    "        f.write(\"output:\" + str(outputs[0:2]) + \"\\n\")\n",
    "        f.write(\"ground true:\" + str(next_state_reward[0:2]) + \"\\n\")\n",
    "    f.close()\n",
    "    return mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_model = TransModel(len(data[0][0]), len(data[0][1]))\n",
    "\n",
    "#check_model.model.load_state_dict(torch.load('./models_mb/NEXUS_MODEL.8.9.19.pt'))\n",
    "\n",
    "#evaluation(check_model, test_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "trans_model = TransModel(len(one_nexus_perspective[0][0]), len(one_nexus_perspective[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([316800, 35]) torch.Size([316800, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [128 x 35], m2: [68 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:268",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c8bc5ffe7cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#print(start, end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrans_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     print(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b77395756a4a>\u001b[0m in \u001b[0;36mpredict_batch\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;31m#reward, next_state = output[:, 0], output[:, 1:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/eecs-fserv/share/lamki/virtualenv/pysc2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b77395756a4a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/eecs-fserv/share/lamki/virtualenv/pysc2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/eecs-fserv/share/lamki/virtualenv/pysc2/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/eecs-fserv/share/lamki/virtualenv/pysc2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/eecs-fserv/share/lamki/virtualenv/pysc2/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/eecs-fserv/share/lamki/virtualenv/pysc2/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 35], m2: [68 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:268"
     ]
    }
   ],
   "source": [
    "\n",
    "state_action = torch.from_numpy(np.stack(train_data[:, 0])).type(FloatTensor)\n",
    "next_state_reward = torch.from_numpy(np.stack(train_data[:, 1])).type(FloatTensor)\n",
    "print(state_action.size(), next_state_reward.size())\n",
    "\n",
    "for epoch in tqdm.tqdm(range(10000)):\n",
    "    loss = 0\n",
    "    s = np.arange(state_action.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    train_x = state_action[s]\n",
    "    train_y = next_state_reward[s]\n",
    "    for i in range(state_action.shape[0] // batch_size + 1):\n",
    "        if (i + 1) * batch_size <= state_action.shape[0]:\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "        else:\n",
    "            start = i * batch_size\n",
    "            end = state_action.shape[0]\n",
    "        #print(start, end)\n",
    "        inputs, ground_true = train_x[start : end, :], train_y[start : end, :]\n",
    "        outputs = trans_model.predict_batch(inputs)\n",
    "        loss += trans_model.fit(outputs, ground_true)\n",
    "#     print(epoch)\n",
    "    summary_test.add_scalars(\"MSE\",{'Train MSE': float(loss / (state_action.shape[0] // batch_size + 1) )}, epoch)\n",
    "    evaluation(trans_model, test_data, epoch)\n",
    "    #break\n",
    "    if epoch % 1000 == 0 and epoch != 0:\n",
    "        print(epoch)\n",
    "        trans_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
